{"ast":null,"code":"/*\n  Corpus class for parsing and analysing corpora\n  Copyright (C) 2019 Hugo W.L. ter Doest\n\n  This program is free software: you can redistribute it and/or modify\n  it under the terms of the GNU General Public License as published by\n  the Free Software Foundation, either version 3 of the License, or\n  (at your option) any later version.\n\n  This program is distributed in the hope that it will be useful,\n  but WITHOUT ANY WARRANTY; without even the implied warranty of\n  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n  GNU General Public License for more details.\n\n  You should have received a copy of the GNU General Public License\n  along with this program.  If not, see <http://www.gnu.org/licenses/>.\n*/\n\n'use strict';\n\nconst Lexicon = require('./Lexicon');\nconst BROWN = 1;\nconst JSON = 2;\n\n// sentences: an array of annotated sentences\n// A sentence is an array of annotated tokens\n// A token is an object with (token, tag, testTag, ruleList)\nfunction Corpus(data, typeOfCorpus, SentenceClass) {\n  this.wordCount = 0;\n  this.sentences = [];\n  const that = this;\n  if (data) {\n    // For other types of corpora add a case here and supply a parsing method\n    switch (typeOfCorpus) {\n      case BROWN:\n        this.parseBrownCorpus(data, SentenceClass);\n        break;\n      case JSON:\n        // Assume it is a JSON object of a corpus\n        data.sentences.forEach(function (s) {\n          const taggedSentence = new SentenceClass(s.taggedWords);\n          that.sentences.push(taggedSentence);\n          that.wordCount += s.taggedWords.length;\n        });\n        break;\n    }\n  }\n}\n\n// data is raw text\n// A corpus parsing method should split the corpus in sentences each of which\n// consist of an array of tokens.\nCorpus.prototype.parseBrownCorpus = function (data, SentenceClass) {\n  const that = this;\n  const lines = data.split('\\n');\n  lines.forEach(function (line) {\n    const trimmedLine = line.trim();\n    // Only parse lines that contain characters\n    if (trimmedLine !== '') {\n      const taggedSentence = new SentenceClass();\n      const tokens = line.trim().split(/\\s+/);\n      tokens.forEach(function (token) {\n        that.wordCount++;\n        // Create a tagged sentences consisting of tokens\n        const wordPlusTag = token.split('_');\n        taggedSentence.addTaggedWord(wordPlusTag[0], wordPlusTag[1]);\n      });\n\n      // Add the sentence to the corpus\n      that.sentences.push(taggedSentence);\n    }\n  });\n};\n\n// Returns an array of all POS tags used in the corpus\nCorpus.prototype.getTags = function () {\n  return Object.keys(this.posTags);\n};\n\n// Splits the corpus in a training and testing set.\n// percentageTrain is the size of the training corpus in percent\n// Returns an array with two elements: training corpus, testing corpus\nCorpus.prototype.splitInTrainAndTest = function (percentageTrain) {\n  const corpusTrain = new Corpus();\n  const corpusTest = new Corpus();\n  const p = percentageTrain / 100;\n  this.sentences.forEach(function (sentence, i) {\n    if (Math.random() < p) {\n      corpusTrain.sentences.push(sentence);\n    } else {\n      corpusTest.sentences.push(sentence);\n    }\n  });\n  return [corpusTrain, corpusTest];\n};\n\n// Analyses the corpus:\n// - registers used POS tags\n// - records the frequency of POS tag for each word\nCorpus.prototype.analyse = function () {\n  this.tagFrequencies = {};\n  this.posTags = {};\n  this.wordCount = 0;\n  const that = this;\n  this.sentences.forEach(function (sentence) {\n    sentence.taggedWords.forEach(function (token) {\n      that.wordCount++;\n\n      // Register the tags used in the corpus\n      that.posTags[token.tag] = true;\n\n      // Register the frequency of the tag\n      if (!that.tagFrequencies[token.token]) {\n        that.tagFrequencies[token.token] = {};\n      }\n      if (!that.tagFrequencies[token.token][token.tag]) {\n        that.tagFrequencies[token.token][token.tag] = 0;\n      }\n      that.tagFrequencies[token.token][token.tag]++;\n    });\n  });\n};\n\n// Creates a lexicon by taking the most frequently occurring tag of a word\n// as the right tag\nCorpus.prototype.buildLexicon = function () {\n  const lexicon = new Lexicon();\n  const that = this;\n  this.analyse();\n  Object.keys(this.tagFrequencies).forEach(function (token) {\n    const catToFreq = that.tagFrequencies[token];\n    const categories = Object.keys(catToFreq);\n    function compareByFrequency(a, b) {\n      if (catToFreq[a] > catToFreq[b]) {\n        return -1;\n      } else {\n        if (catToFreq[a] < catToFreq[b]) {\n          return 1;\n        } else {\n          return 0;\n        }\n      }\n    }\n    const sortedCategories = categories.sort(compareByFrequency);\n    lexicon.addWord(token, sortedCategories);\n  });\n  return lexicon;\n};\nCorpus.prototype.tag = function (lexicon) {\n  this.sentences.forEach(function (sentence) {\n    sentence.taggedWords.forEach(function (token) {\n      // tagWord returns a list of categories, take the first category\n      token.testTag = lexicon.tagWord(token.token)[0];\n    });\n  });\n};\nCorpus.prototype.nrSentences = function () {\n  return this.sentences.length;\n};\nCorpus.prototype.nrWords = function () {\n  return this.wordCount;\n};\nCorpus.prototype.generateFeatures = function () {\n  let features = [];\n  this.sentences.forEach(function (sentence) {\n    features = sentence.generateFeatures(features);\n  });\n  // console.log(JSON.stringify(features));\n  return features;\n};\nCorpus.prototype.prettyPrint = function () {\n  this.sentences.forEach(function (sentence, index) {\n    // logger.debug(\"sentence no \" + index + \"\\n\" +\n    //  JSON.stringify(sentence, null, 2));\n  });\n};\nmodule.exports = Corpus;","map":{"version":3,"names":["Lexicon","require","BROWN","JSON","Corpus","data","typeOfCorpus","SentenceClass","wordCount","sentences","that","parseBrownCorpus","forEach","s","taggedSentence","taggedWords","push","length","prototype","lines","split","line","trimmedLine","trim","tokens","token","wordPlusTag","addTaggedWord","getTags","Object","keys","posTags","splitInTrainAndTest","percentageTrain","corpusTrain","corpusTest","p","sentence","i","Math","random","analyse","tagFrequencies","tag","buildLexicon","lexicon","catToFreq","categories","compareByFrequency","a","b","sortedCategories","sort","addWord","testTag","tagWord","nrSentences","nrWords","generateFeatures","features","prettyPrint","index","module","exports"],"sources":["/Users/gauravsain/Desktop/PEPCODING/DEV/React/threadsandtrends/node_modules/natural/lib/natural/brill_pos_tagger/lib/Corpus.js"],"sourcesContent":["/*\n  Corpus class for parsing and analysing corpora\n  Copyright (C) 2019 Hugo W.L. ter Doest\n\n  This program is free software: you can redistribute it and/or modify\n  it under the terms of the GNU General Public License as published by\n  the Free Software Foundation, either version 3 of the License, or\n  (at your option) any later version.\n\n  This program is distributed in the hope that it will be useful,\n  but WITHOUT ANY WARRANTY; without even the implied warranty of\n  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n  GNU General Public License for more details.\n\n  You should have received a copy of the GNU General Public License\n  along with this program.  If not, see <http://www.gnu.org/licenses/>.\n*/\n\n'use strict'\n\nconst Lexicon = require('./Lexicon')\n\nconst BROWN = 1\nconst JSON = 2\n\n// sentences: an array of annotated sentences\n// A sentence is an array of annotated tokens\n// A token is an object with (token, tag, testTag, ruleList)\nfunction Corpus (data, typeOfCorpus, SentenceClass) {\n  this.wordCount = 0\n  this.sentences = []\n  const that = this\n  if (data) {\n    // For other types of corpora add a case here and supply a parsing method\n    switch (typeOfCorpus) {\n      case BROWN:\n        this.parseBrownCorpus(data, SentenceClass)\n        break\n      case JSON:\n        // Assume it is a JSON object of a corpus\n        data.sentences.forEach(function (s) {\n          const taggedSentence = new SentenceClass(s.taggedWords)\n          that.sentences.push(taggedSentence)\n          that.wordCount += s.taggedWords.length\n        })\n        break\n    }\n  }\n}\n\n// data is raw text\n// A corpus parsing method should split the corpus in sentences each of which\n// consist of an array of tokens.\nCorpus.prototype.parseBrownCorpus = function (data, SentenceClass) {\n  const that = this\n\n  const lines = data.split('\\n')\n  lines.forEach(function (line) {\n    const trimmedLine = line.trim()\n    // Only parse lines that contain characters\n    if (trimmedLine !== '') {\n      const taggedSentence = new SentenceClass()\n      const tokens = line.trim().split(/\\s+/)\n      tokens.forEach(function (token) {\n        that.wordCount++\n        // Create a tagged sentences consisting of tokens\n        const wordPlusTag = token.split('_')\n        taggedSentence.addTaggedWord(wordPlusTag[0], wordPlusTag[1])\n      })\n\n      // Add the sentence to the corpus\n      that.sentences.push(taggedSentence)\n    }\n  })\n}\n\n// Returns an array of all POS tags used in the corpus\nCorpus.prototype.getTags = function () {\n  return Object.keys(this.posTags)\n}\n\n// Splits the corpus in a training and testing set.\n// percentageTrain is the size of the training corpus in percent\n// Returns an array with two elements: training corpus, testing corpus\nCorpus.prototype.splitInTrainAndTest = function (percentageTrain) {\n  const corpusTrain = new Corpus()\n  const corpusTest = new Corpus()\n\n  const p = percentageTrain / 100\n  this.sentences.forEach(function (sentence, i) {\n    if (Math.random() < p) {\n      corpusTrain.sentences.push(sentence)\n    } else {\n      corpusTest.sentences.push(sentence)\n    }\n  })\n  return [corpusTrain, corpusTest]\n}\n\n// Analyses the corpus:\n// - registers used POS tags\n// - records the frequency of POS tag for each word\nCorpus.prototype.analyse = function () {\n  this.tagFrequencies = {}\n  this.posTags = {}\n  this.wordCount = 0\n\n  const that = this\n  this.sentences.forEach(function (sentence) {\n    sentence.taggedWords.forEach(function (token) {\n      that.wordCount++\n\n      // Register the tags used in the corpus\n      that.posTags[token.tag] = true\n\n      // Register the frequency of the tag\n      if (!that.tagFrequencies[token.token]) {\n        that.tagFrequencies[token.token] = {}\n      }\n      if (!that.tagFrequencies[token.token][token.tag]) {\n        that.tagFrequencies[token.token][token.tag] = 0\n      }\n      that.tagFrequencies[token.token][token.tag]++\n    })\n  })\n}\n\n// Creates a lexicon by taking the most frequently occurring tag of a word\n// as the right tag\nCorpus.prototype.buildLexicon = function () {\n  const lexicon = new Lexicon()\n  const that = this\n\n  this.analyse()\n  Object.keys(this.tagFrequencies).forEach(function (token) {\n    const catToFreq = that.tagFrequencies[token]\n    const categories = Object.keys(catToFreq)\n\n    function compareByFrequency (a, b) {\n      if (catToFreq[a] > catToFreq[b]) {\n        return -1\n      } else {\n        if (catToFreq[a] < catToFreq[b]) {\n          return 1\n        } else {\n          return 0\n        }\n      }\n    }\n\n    const sortedCategories = categories.sort(compareByFrequency)\n    lexicon.addWord(token, sortedCategories)\n  })\n  return lexicon\n}\n\nCorpus.prototype.tag = function (lexicon) {\n  this.sentences.forEach(function (sentence) {\n    sentence.taggedWords.forEach(function (token) {\n      // tagWord returns a list of categories, take the first category\n      token.testTag = lexicon.tagWord(token.token)[0]\n    })\n  })\n}\n\nCorpus.prototype.nrSentences = function () {\n  return this.sentences.length\n}\n\nCorpus.prototype.nrWords = function () {\n  return this.wordCount\n}\n\nCorpus.prototype.generateFeatures = function () {\n  let features = []\n  this.sentences.forEach(function (sentence) {\n    features = sentence.generateFeatures(features)\n  })\n  // console.log(JSON.stringify(features));\n  return features\n}\n\nCorpus.prototype.prettyPrint = function () {\n  this.sentences.forEach(function (sentence, index) {\n    // logger.debug(\"sentence no \" + index + \"\\n\" +\n    //  JSON.stringify(sentence, null, 2));\n  })\n}\n\nmodule.exports = Corpus\n"],"mappings":"AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,YAAY;;AAEZ,MAAMA,OAAO,GAAGC,OAAO,CAAC,WAAW,CAAC;AAEpC,MAAMC,KAAK,GAAG,CAAC;AACf,MAAMC,IAAI,GAAG,CAAC;;AAEd;AACA;AACA;AACA,SAASC,MAAMA,CAAEC,IAAI,EAAEC,YAAY,EAAEC,aAAa,EAAE;EAClD,IAAI,CAACC,SAAS,GAAG,CAAC;EAClB,IAAI,CAACC,SAAS,GAAG,EAAE;EACnB,MAAMC,IAAI,GAAG,IAAI;EACjB,IAAIL,IAAI,EAAE;IACR;IACA,QAAQC,YAAY;MAClB,KAAKJ,KAAK;QACR,IAAI,CAACS,gBAAgB,CAACN,IAAI,EAAEE,aAAa,CAAC;QAC1C;MACF,KAAKJ,IAAI;QACP;QACAE,IAAI,CAACI,SAAS,CAACG,OAAO,CAAC,UAAUC,CAAC,EAAE;UAClC,MAAMC,cAAc,GAAG,IAAIP,aAAa,CAACM,CAAC,CAACE,WAAW,CAAC;UACvDL,IAAI,CAACD,SAAS,CAACO,IAAI,CAACF,cAAc,CAAC;UACnCJ,IAAI,CAACF,SAAS,IAAIK,CAAC,CAACE,WAAW,CAACE,MAAM;QACxC,CAAC,CAAC;QACF;IACJ;EACF;AACF;;AAEA;AACA;AACA;AACAb,MAAM,CAACc,SAAS,CAACP,gBAAgB,GAAG,UAAUN,IAAI,EAAEE,aAAa,EAAE;EACjE,MAAMG,IAAI,GAAG,IAAI;EAEjB,MAAMS,KAAK,GAAGd,IAAI,CAACe,KAAK,CAAC,IAAI,CAAC;EAC9BD,KAAK,CAACP,OAAO,CAAC,UAAUS,IAAI,EAAE;IAC5B,MAAMC,WAAW,GAAGD,IAAI,CAACE,IAAI,CAAC,CAAC;IAC/B;IACA,IAAID,WAAW,KAAK,EAAE,EAAE;MACtB,MAAMR,cAAc,GAAG,IAAIP,aAAa,CAAC,CAAC;MAC1C,MAAMiB,MAAM,GAAGH,IAAI,CAACE,IAAI,CAAC,CAAC,CAACH,KAAK,CAAC,KAAK,CAAC;MACvCI,MAAM,CAACZ,OAAO,CAAC,UAAUa,KAAK,EAAE;QAC9Bf,IAAI,CAACF,SAAS,EAAE;QAChB;QACA,MAAMkB,WAAW,GAAGD,KAAK,CAACL,KAAK,CAAC,GAAG,CAAC;QACpCN,cAAc,CAACa,aAAa,CAACD,WAAW,CAAC,CAAC,CAAC,EAAEA,WAAW,CAAC,CAAC,CAAC,CAAC;MAC9D,CAAC,CAAC;;MAEF;MACAhB,IAAI,CAACD,SAAS,CAACO,IAAI,CAACF,cAAc,CAAC;IACrC;EACF,CAAC,CAAC;AACJ,CAAC;;AAED;AACAV,MAAM,CAACc,SAAS,CAACU,OAAO,GAAG,YAAY;EACrC,OAAOC,MAAM,CAACC,IAAI,CAAC,IAAI,CAACC,OAAO,CAAC;AAClC,CAAC;;AAED;AACA;AACA;AACA3B,MAAM,CAACc,SAAS,CAACc,mBAAmB,GAAG,UAAUC,eAAe,EAAE;EAChE,MAAMC,WAAW,GAAG,IAAI9B,MAAM,CAAC,CAAC;EAChC,MAAM+B,UAAU,GAAG,IAAI/B,MAAM,CAAC,CAAC;EAE/B,MAAMgC,CAAC,GAAGH,eAAe,GAAG,GAAG;EAC/B,IAAI,CAACxB,SAAS,CAACG,OAAO,CAAC,UAAUyB,QAAQ,EAAEC,CAAC,EAAE;IAC5C,IAAIC,IAAI,CAACC,MAAM,CAAC,CAAC,GAAGJ,CAAC,EAAE;MACrBF,WAAW,CAACzB,SAAS,CAACO,IAAI,CAACqB,QAAQ,CAAC;IACtC,CAAC,MAAM;MACLF,UAAU,CAAC1B,SAAS,CAACO,IAAI,CAACqB,QAAQ,CAAC;IACrC;EACF,CAAC,CAAC;EACF,OAAO,CAACH,WAAW,EAAEC,UAAU,CAAC;AAClC,CAAC;;AAED;AACA;AACA;AACA/B,MAAM,CAACc,SAAS,CAACuB,OAAO,GAAG,YAAY;EACrC,IAAI,CAACC,cAAc,GAAG,CAAC,CAAC;EACxB,IAAI,CAACX,OAAO,GAAG,CAAC,CAAC;EACjB,IAAI,CAACvB,SAAS,GAAG,CAAC;EAElB,MAAME,IAAI,GAAG,IAAI;EACjB,IAAI,CAACD,SAAS,CAACG,OAAO,CAAC,UAAUyB,QAAQ,EAAE;IACzCA,QAAQ,CAACtB,WAAW,CAACH,OAAO,CAAC,UAAUa,KAAK,EAAE;MAC5Cf,IAAI,CAACF,SAAS,EAAE;;MAEhB;MACAE,IAAI,CAACqB,OAAO,CAACN,KAAK,CAACkB,GAAG,CAAC,GAAG,IAAI;;MAE9B;MACA,IAAI,CAACjC,IAAI,CAACgC,cAAc,CAACjB,KAAK,CAACA,KAAK,CAAC,EAAE;QACrCf,IAAI,CAACgC,cAAc,CAACjB,KAAK,CAACA,KAAK,CAAC,GAAG,CAAC,CAAC;MACvC;MACA,IAAI,CAACf,IAAI,CAACgC,cAAc,CAACjB,KAAK,CAACA,KAAK,CAAC,CAACA,KAAK,CAACkB,GAAG,CAAC,EAAE;QAChDjC,IAAI,CAACgC,cAAc,CAACjB,KAAK,CAACA,KAAK,CAAC,CAACA,KAAK,CAACkB,GAAG,CAAC,GAAG,CAAC;MACjD;MACAjC,IAAI,CAACgC,cAAc,CAACjB,KAAK,CAACA,KAAK,CAAC,CAACA,KAAK,CAACkB,GAAG,CAAC,EAAE;IAC/C,CAAC,CAAC;EACJ,CAAC,CAAC;AACJ,CAAC;;AAED;AACA;AACAvC,MAAM,CAACc,SAAS,CAAC0B,YAAY,GAAG,YAAY;EAC1C,MAAMC,OAAO,GAAG,IAAI7C,OAAO,CAAC,CAAC;EAC7B,MAAMU,IAAI,GAAG,IAAI;EAEjB,IAAI,CAAC+B,OAAO,CAAC,CAAC;EACdZ,MAAM,CAACC,IAAI,CAAC,IAAI,CAACY,cAAc,CAAC,CAAC9B,OAAO,CAAC,UAAUa,KAAK,EAAE;IACxD,MAAMqB,SAAS,GAAGpC,IAAI,CAACgC,cAAc,CAACjB,KAAK,CAAC;IAC5C,MAAMsB,UAAU,GAAGlB,MAAM,CAACC,IAAI,CAACgB,SAAS,CAAC;IAEzC,SAASE,kBAAkBA,CAAEC,CAAC,EAAEC,CAAC,EAAE;MACjC,IAAIJ,SAAS,CAACG,CAAC,CAAC,GAAGH,SAAS,CAACI,CAAC,CAAC,EAAE;QAC/B,OAAO,CAAC,CAAC;MACX,CAAC,MAAM;QACL,IAAIJ,SAAS,CAACG,CAAC,CAAC,GAAGH,SAAS,CAACI,CAAC,CAAC,EAAE;UAC/B,OAAO,CAAC;QACV,CAAC,MAAM;UACL,OAAO,CAAC;QACV;MACF;IACF;IAEA,MAAMC,gBAAgB,GAAGJ,UAAU,CAACK,IAAI,CAACJ,kBAAkB,CAAC;IAC5DH,OAAO,CAACQ,OAAO,CAAC5B,KAAK,EAAE0B,gBAAgB,CAAC;EAC1C,CAAC,CAAC;EACF,OAAON,OAAO;AAChB,CAAC;AAEDzC,MAAM,CAACc,SAAS,CAACyB,GAAG,GAAG,UAAUE,OAAO,EAAE;EACxC,IAAI,CAACpC,SAAS,CAACG,OAAO,CAAC,UAAUyB,QAAQ,EAAE;IACzCA,QAAQ,CAACtB,WAAW,CAACH,OAAO,CAAC,UAAUa,KAAK,EAAE;MAC5C;MACAA,KAAK,CAAC6B,OAAO,GAAGT,OAAO,CAACU,OAAO,CAAC9B,KAAK,CAACA,KAAK,CAAC,CAAC,CAAC,CAAC;IACjD,CAAC,CAAC;EACJ,CAAC,CAAC;AACJ,CAAC;AAEDrB,MAAM,CAACc,SAAS,CAACsC,WAAW,GAAG,YAAY;EACzC,OAAO,IAAI,CAAC/C,SAAS,CAACQ,MAAM;AAC9B,CAAC;AAEDb,MAAM,CAACc,SAAS,CAACuC,OAAO,GAAG,YAAY;EACrC,OAAO,IAAI,CAACjD,SAAS;AACvB,CAAC;AAEDJ,MAAM,CAACc,SAAS,CAACwC,gBAAgB,GAAG,YAAY;EAC9C,IAAIC,QAAQ,GAAG,EAAE;EACjB,IAAI,CAAClD,SAAS,CAACG,OAAO,CAAC,UAAUyB,QAAQ,EAAE;IACzCsB,QAAQ,GAAGtB,QAAQ,CAACqB,gBAAgB,CAACC,QAAQ,CAAC;EAChD,CAAC,CAAC;EACF;EACA,OAAOA,QAAQ;AACjB,CAAC;AAEDvD,MAAM,CAACc,SAAS,CAAC0C,WAAW,GAAG,YAAY;EACzC,IAAI,CAACnD,SAAS,CAACG,OAAO,CAAC,UAAUyB,QAAQ,EAAEwB,KAAK,EAAE;IAChD;IACA;EAAA,CACD,CAAC;AACJ,CAAC;AAEDC,MAAM,CAACC,OAAO,GAAG3D,MAAM"},"metadata":{},"sourceType":"script","externalDependencies":[]}